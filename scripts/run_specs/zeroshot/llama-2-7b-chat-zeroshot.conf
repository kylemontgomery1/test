entries: [
    # AddSub
    {description: "addsub:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # AQuA
    {description: "aqua:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # BoolQ
    {description: "boolq:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # CivilComments
    {description: "civil_comments:model=local/llama-2-7b-chat,max_train_instances=0,demographic=all", priority: 1} 
    {description: "civil_comments:model=local/llama-2-7b-chat,max_train_instances=0,demographic=male", priority: 1}
    {description: "civil_comments:model=local/llama-2-7b-chat,max_train_instances=0,demographic=female", priority: 1}
    {description: "civil_comments:model=local/llama-2-7b-chat,max_train_instances=0,demographic=LGBTQ", priority: 1}
    {description: "civil_comments:model=local/llama-2-7b-chat,max_train_instances=0,demographic=christian", priority: 1}
    {description: "civil_comments:model=local/llama-2-7b-chat,max_train_instances=0,demographic=muslim", priority: 1}
    {description: "civil_comments:model=local/llama-2-7b-chat,max_train_instances=0,demographic=other_religions", priority: 1}
    {description: "civil_comments:model=local/llama-2-7b-chat,max_train_instances=0,demographic=black", priority: 1}
    {description: "civil_comments:model=local/llama-2-7b-chat,max_train_instances=0,demographic=white", priority: 1}

    # CNN/Daily Mail
    {description: "summarization_cnndm:model=local/llama-2-7b-chat,max_train_instances=0,temperature=0.3,device=cpu", priority: 1}

    # Coin Flip
    {description: "coin:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # CommonsenseQA
    {description: "commonsense_qa:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # Date Understanding
    {description: "big_bench_hard:model=local/llama-2-7b-chat,max_train_instances=0,dataset=date_understanding", priority: 1}

    # GSM8K
    {description: "gsm:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # HellaSwag
    {description: "commonsense:model=local/llama-2-7b-chat,max_train_instances=0,dataset=hellaswag,method=multiple_choice_joint", priority: 1}

    # IMDB
    {description: "imdb:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # Last Letter Concatenation
    {description: "letter:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # MMLU
    {description: "mmlu:model=local/llama-2-7b-chat,max_train_instances=0,subject=abstract_algebra", priority: 1}
    {description: "mmlu:model=local/llama-2-7b-chat,max_train_instances=0,subject=college_chemistry", priority: 1}
    {description: "mmlu:model=local/llama-2-7b-chat,max_train_instances=0,subject=computer_security", priority: 1}
    {description: "mmlu:model=local/llama-2-7b-chat,max_train_instances=0,subject=econometrics", priority: 1}
    {description: "mmlu:model=local/llama-2-7b-chat,max_train_instances=0,subject=us_foreign_policy", priority: 1}

    # MS MARCO
    {description: "msmarco:model=local/llama-2-7b-chat,max_train_instances=0,track=regular,valid_topk=30", priority: 1}
    {description: "msmarco:model=local/llama-2-7b-chat,max_train_instances=0,track=trec,valid_topk=30", priority: 1}

    # MultiArith
    {description: "multi_arith:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # NarrativeQA
    {description: "narrative_qa:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # NaturalQA
    {description: "natural_qa:model=local/llama-2-7b-chat,max_train_instances=0,mode=closedbook", priority: 1}
    {description: "natural_qa:model=local/llama-2-7b-chat,max_train_instances=0,mode=openbook_longans", priority: 1}

    # NewsQA
    # {description: "news_qa:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # OpenbookQA
    {description: "commonsense:model=local/llama-2-7b-chat,max_train_instances=0,dataset=openbookqa,method=multiple_choice_joint", priority: 1}

    # QuAC
    {description: "quac:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # RAFT
    {description: "raft:subset=ade_corpus_v2,model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}
    {description: "raft:subset=banking_77,model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}
    {description: "raft:subset=neurips_impact_statement_risks,model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}
    {description: "raft:subset=one_stop_english,model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}
    {description: "raft:subset=overruling,model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}
    {description: "raft:subset=semiconductor_org_types,model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}
    {description: "raft:subset=tweet_eval_hate,model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}
    {description: "raft:subset=twitter_complaints,model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}
    {description: "raft:subset=systematic_review_inclusion,model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}
    {description: "raft:subset=tai_safety_research,model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}
    {description: "raft:subset=terms_of_service,model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # Shuffled Objects
    {description: "big_bench_hard:model=local/llama-2-7b-chat,max_train_instances=0,dataset=tracking_shuffled_objects_three_objects", priority: 1}
    {description: "big_bench_hard:model=local/llama-2-7b-chat,max_train_instances=0,dataset=tracking_shuffled_objects_five_objects", priority: 1}
    {description: "big_bench_hard:model=local/llama-2-7b-chat,max_train_instances=0,dataset=tracking_shuffled_objects_seven_objects", priority: 1}

    # SingleEq
    {description: "singleeq:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}

    # StrategyQA
    {description: "big_bench:model=local/llama-2-7b-chat,max_train_instances=0,task=strategyqa,subtask=", priority: 1}

    # SVAMP
    {description: "svamp:model=local/llama-2-7b-chat,max_train_instances=0", priority: 1}
   
    # TruthfulQA
    {description: "truthful_qa:model=local/llama-2-7b-chat,max_train_instances=0,task=mc_single", priority: 1}

    # XSUM
    {description: "summarization_xsum_sampled:model=local/llama-2-7b-chat,max_train_instances=0,temperature=0.3,device=cpu", priority: 1}
]